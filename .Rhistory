knitr::opts_chunk$set(echo = TRUE)
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
# usage
packages <- c("ggplot2", "dataMaid","readxl")
ipak(packages)
read_xlsx(path = "C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract")
<-read_xlsx(path = "C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/test.xlsx")
test<-read_xlsx(path = "C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/test.xlsx")
test<-read_xlsx(path = "C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Test.xlsx")
test<-read_xlsx(path = "C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Test.xlsx",sheet = "Sheet2")
View(test)
test<-read_xlsx(path = "C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Test.xlsx",sheet = "Sheet2")
test<-read_xlsx(path = "C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Test.xlsx",sheet = "Sheet2")
scopus14<-read.csv("C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Abstract scrapes/scopus(14).csv" )
View(scopus14)
View(scopus14)
for (i in 14:58) {
scopus[i]<-read.csv(paste("C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Abstract scrapes/scopus(",i,").csv" ))
}
for (i in 14:58) {
scopus[i]<-read.csv(paste("C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Abstract scrapes/scopus(",[i],").csv" ))
for (i in 14:58) {
scopus[i]<-read.csv(paste("C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Abstract scrapes/scopus(",i,").csv",sep = "" ))
}
for (i in 14:58) {
"scopus"[i]<-read.csv(paste("C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Abstract scrapes/scopus(",i,").csv",sep = "" ))
}
for (i in 14:58) {
scopus[i]<-read.csv(paste("C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Abstract scrapes/scopus(",i,").csv",sep = "" ))
}
for (i in 14:58) {
scopus<-data.frame(matrix(23,45))
scopus[i]<-read.csv(paste("C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Abstract scrapes/scopus(",i,").csv",sep = "" ))
}
scopus<-data.frame(matrix(0,0))
for (i in 14:58) {
scopus<-data.frame(matrix(0,0))
scopus[i]<-read.csv(paste("C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Abstract scrapes/scopus(",i,").csv",sep = "" ))
}
test<-read_xlsx(path = "C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Test.xlsx",sheet = "Sheet2")
scopus14<-read.csv("C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Abstract scrapes/scopus(14).csv" )
for (i in 14:58) {
scopus<-data.frame(matrix(0,0))
scopus[i]<-read.csv(paste("C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Abstract scrapes/scopus(",i,").csv",sep = "" ))
}
View(scopus14)
for (i in 14:58) {
scopus[i]<-data.frame(matrix(0,0))
scopus[i]<-read.csv(paste("C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Abstract scrapes/scopus(",i,").csv",sep = "" ))
}
test<-read_xlsx(path = "C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Test.xlsx",sheet = "Sheet2")
for (i in 14:58) {
scopus[i]<-data.frame(matrix(0,0))
scopus[i]<-read.csv(paste("C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Abstract scrapes/scopus(",i,").csv",sep = "" ))
}
for (i in 14:58) {
scopus[i]<-as.data.frame(read.csv(paste("C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Abstract scrapes/scopus(",i,").csv",sep = "" )))
}
dir()
getwd()
dir()
##Read files named xyz1111.csv, xyz2222.csv, etc.
filenames <- list.files(path="C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Abstract scrapes",pattern="xyz+.*csv")
##Read files named xyz1111.csv, xyz2222.csv, etc.
filenames <- list.files(path="C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Abstract scrapes/",pattern="xyz+.*csv")
##Read files named xyz1111.csv, xyz2222.csv, etc.
filenames <- list.files(path="C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract",pattern="xyz+.*csv")
##Read files named xyz1111.csv, xyz2222.csv, etc.
filenames <- list.files(path="C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Abstract scrapes",pattern="scopus+.*csv")
##Create list of data frame names without the ".csv" part
names <-substr(filenames,1,7))
##Create list of data frame names without the ".csv" part
names <-substr(filenames,1,7)
##Create list of data frame names without the ".csv" part
names <-substr(filenames,2,7)
##Create list of data frame names without the ".csv" part
names <-substr(filenames,0,7)
##Create list of data frame names without the ".csv" part
names <-substr(filenames,1,7)
##Create list of data frame names without the ".csv" part
names <-substr(filenames,1,6)
##Create list of data frame names without the ".csv" part
names <-substr(filenames,1,10)
###Load all files
for(i in names){
filepath <- file.path("C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Abstract scrapes",paste(i,".csv",sep=""))
assign(i, read.delim(filepath,
colClasses=c("character","factor",rep("numeric",4)),
sep = "\t"))
}
View(`scopus(58)`)
###Load all files
for(i in names){
filepath <- file.path("C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Abstract scrapes",paste(i,".csv",sep=""))
assign(i, read.delim(filepath,colClasses=c("character","factor",rep("numeric",4)),sep = ","))
}
test<-read_xlsx(path = "C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Test.xlsx",sheet = "Sheet2")
##Read files named xyz1111.csv, xyz2222.csv, etc.
filenames <- list.files(path="C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Abstract scrapes",pattern="scopus+.*csv")
##Create list of data frame names without the ".csv" part
names <-substr(filenames,1,10)
###Load all files
for(i in names){
filepath <- file.path("C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Abstract scrapes",paste(i,".csv",sep=""))
assign(i, read.delim(filepath,colClasses=c("character","factor",rep("numeric",4)),sep = ","))
}
###Load all files
for(i in names){
filepath <- file.path("C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Abstract scrapes",paste(i,".csv",sep=""))
assign(i, read.csv(filepath,sep = ","))
}
View(`scopus(58)`)
#Merge with data
`scopus(14)`$DOI
#Merge with data
`scopus(14)`$Year
#Merge with data
`scopus(14)`$Keyword<-test$Keyword[which(test$Hits>0)]
#Merge with data
test.clean<-test[which(test$Hits>0)]
#Merge with data
transform(test, Hits = as.numeric(Hits))
View(test)
test.clean<-test[which(test$Hits>0)]
#Merge with data
transform(test, Hits = as.numeric(Hits))
#Merge with data
test<-transform(test, Hits = as.numeric(Hits))
View(test)
test.clean<-test[which(test$Hits>0)]
test.clean<-test[which(test$Hits>0)]
test.clean<-test[which(test$Hits>0),]
View(test.clean)
knitr::opts_chunk$set(echo = TRUE)
test<-read_xlsx(path = "C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Test.xlsx",sheet = "Sheet2")
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
# usage
packages <- c("ggplot2", "dataMaid","readxl")
ipak(packages)
```{r}
test<-read_xlsx(path = "C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Test.xlsx",sheet = "Sheet2")
test<-read_xlsx(path = "C:/Users/jj.egb/Dropbox (CBS CIU)/Collective Intelligence Unit/7. project 2019 - 2022 (PU)/B_Research/Literature review/Research Areas+concepts/Data scraping/ScopusScrape - Abstract/Data and grpahs.xlsx",sheet = "Data")
View(test)
DFclean<-test[which(Hits>0)]
DFclean<-test[which(test$Hits>0)]
DFclean<-test[which(test$Hits>0),]
View(DFclean)
DFclean["Abstract",1]
DFclean[1,"Abstract"]
nchar(DFclean[1,"Abstract"])
#load text mining library
library(tm)
#load text mining library
install.packages("tm")
library(tm)
filenames<-DFclean[,"Abstract"]
docs<-Corpus(VectorSource(filenames))
#inspect a particular document in corpus
writeLines(as.character(docs[[30]]))
#load files into corpus
#get listing of .txt files in directory
filenames <- list.files("C:/Users/jj.egb/Downloads/Textmining",pattern=”*.txt”)
#load files into corpus
#get listing of .txt files in directory
filenames <- list.files("C:/Users/jj.egb/Downloads/Textmining",pattern= "*.txt")
#read files into a character vector
files <- lapply(filenames,readLines)
#read files into a character vector
files <- lapply(c("C:\Users\jj.egb\Downloads\Textmining"+filenames),readLines)
#read files into a character vector
files <- lapply(paste("C:\Users\jj.egb\Downloads\Textmining"+filenames),readLines)
#read files into a character vector
files <- lapply(paste("C:\Users\jj.egb\Downloads\Textmining",filenames),readLines)
#read files into a character vector
files <- lapply(paste("C:/Users/jj.egb/Downloads/Textmining",filenames),readLines)
#read files into a character vector
files <- lapply(paste("C:/Users/jj.egb/Downloads/Textmining/",filenames),readLines)
#read files into a character vector
files <- lapply(paste("C:/Users/jj.egb/Downloads/Textmining/"+filenames),readLines)
??paste
#load files into corpus
#get listing of .txt files in directory
filenames <- paste("C:/Users/jj.egb/Downloads/Textmining/",list.files("C:/Users/jj.egb/Downloads/Textmining",pattern= "*.txt"))
#load files into corpus
#get listing of .txt files in directory
filenames <- paste("C:/Users/jj.egb/Downloads/Textmining",list.files("C:/Users/jj.egb/Downloads/Textmining",pattern= "*.txt"))
#load files into corpus
#get listing of .txt files in directory
filenames <- paste("C:/Users/jj.egb/Downloads/Textmining/",list.files("C:/Users/jj.egb/Downloads/Textmining",pattern= "*.txt"))
#load files into corpus
#get listing of .txt files in directory
filenames <- paste("C:/Users/jj.egb/Downloads/Textmining/",list.files("C:/Users/jj.egb/Downloads/Textmining",pattern= "*.txt"),collapse = "")
#load files into corpus
#get listing of .txt files in directory
filenames <- paste("C:/Users/jj.egb/Downloads/Textmining/",list.files("C:/Users/jj.egb/Downloads/Textmining",pattern= "*.txt"))
str(filenames)
class(filenames)
#read files into a character vector
files <- lapply(filenames,readLines)
#load files into corpus
#get listing of .txt files in directory
filenames <- paste("C:/Users/jj.egb/Downloads/Textmining/",list.files("C:/Users/jj.egb/Downloads/Textmining",pattern= "*.txt"),sep = "")
#read files into a character vector
files <- lapply(filenames,readLines)
filenames<-DFclean[,"Abstract"]
filenames<-as.list(DFclean[,"Abstract"])
filenames<-as.list.data.frame(DFclean[,"Abstract"])
filenames<-(DFclean[,"Abstract"])
filenames <- setNames(split(filenames, seq(nrow(filenames))), rownames(filenames))
filenames <- split(filenames, seq(nrow(filenames)))
filenames<-(DFclean[,"Abstract"])
filenames <- split(filenames, seq(nrow(filenames)))
#create corpus from vector
docs <- Corpus(VectorSource(files))
#read files into a character vector
files <- lapply(filenames,readLines)
filenames<-(DFclean[,"Abstract"])
filenames <- as.list(as.data.frame(t(filenames)))
docs<-Corpus(VectorSource(filenames))
#inspect a particular document in corpus
writeLines(as.character(docs[[30]]))
#load files into corpus
#get listing of .txt files in directory
filenames <- paste("C:/Users/jj.egb/Downloads/Textmining/",list.files("C:/Users/jj.egb/Downloads/Textmining",pattern= "*.txt"),sep = "")
#read files into a character vector
files <- lapply(filenames,readLines)
#create corpus from vector
docs <- Corpus(VectorSource(files))
#inspect a particular document in corpus
writeLines(as.character(docs[[30]]))
